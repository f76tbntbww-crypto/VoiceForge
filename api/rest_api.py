# -*- coding: utf-8 -*-
"""
VoiceForge REST API Server

æä¾› RESTful API æ¥å£ï¼š
- /          - æœåŠ¡çŠ¶æ€
- /asr       - è¯­éŸ³è¯†åˆ«
- /tts       - è¯­éŸ³åˆæˆ
- /chat      - AIå¯¹è¯
- /complete  - å®Œæ•´æµç¨‹ (ASR+LLM+TTS)
- /voices    - è·å–éŸ³è‰²åˆ—è¡¨

å¯åŠ¨æ–¹å¼ï¼š
    python api/rest_api.py

æˆ–ä½¿ç”¨è„šæœ¬ï¼š
    ..\scripts\start_api.bat
"""

import os
import sys
import json
import tempfile
import subprocess
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from flask import Flask, request, jsonify, send_file
import yaml

# å¯¼å…¥æ’ä»¶
from plugins.asr.sensevoice import SenseVoiceASR
from plugins.tts.cosyvoice import CosyVoiceTTS

# ==================== åŠ è½½é…ç½® ====================


def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config_path = project_root / "config.yaml"
    if not config_path.exists():
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        sys.exit(1)

    with open(config_path, "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)

    # å¤„ç†ç›¸å¯¹è·¯å¾„
    config = resolve_paths(config, project_root)
    return config


def resolve_paths(config, root_path):
    """å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„"""
    paths = config.get("paths", {})

    # å¤„ç† models è·¯å¾„
    if "models" in paths:
        for key, path in paths["models"].items():
            if not os.path.isabs(path):
                paths["models"][key] = os.path.join(root_path, path)

    # å¤„ç† libs è·¯å¾„
    if "libs" in paths:
        for key, path in paths["libs"].items():
            if not os.path.isabs(path):
                paths["libs"][key] = os.path.join(root_path, path)
            # æ·»åŠ åˆ° Python è·¯å¾„
            if path not in sys.path:
                sys.path.insert(0, paths["libs"][key])

    return config


# åŠ è½½é…ç½®
config = load_config()
system_config = config.get("system", {})
models_config = config.get("models", {})
paths_config = config.get("paths", {})

# ==================== åˆå§‹åŒ– Flask ====================

app = Flask(__name__)

# ==================== åŠ è½½æ¨¡å‹ ====================

print("=" * 60)
print(f"ğŸš€ VoiceForge API Server")
print(f"   ç‰ˆæœ¬: {system_config.get('version', '1.0.0-preview')}")
print("=" * 60)

# åŠ è½½ ASR
asr_model = None
if models_config.get("asr", {}).get("enabled", True):
    print("\nğŸ”„ åŠ è½½ ASR æ¨¡å‹...")
    asr_config = models_config["asr"].copy()
    asr_config["model_path"] = paths_config.get("models", {}).get("asr")
    asr_model = SenseVoiceASR(asr_config)
    asr_model.load(asr_config)
else:
    print("\nâš ï¸ ASR å·²ç¦ç”¨")

# åŠ è½½ TTS
tts_model = None
if models_config.get("tts", {}).get("enabled", True):
    print("\nğŸ”„ åŠ è½½ TTS æ¨¡å‹...")
    tts_config = models_config["tts"].copy()
    tts_config["model_path"] = paths_config.get("models", {}).get("tts")
    tts_config["cosyvoice_lib"] = paths_config.get("libs", {}).get("cosyvoice")
    tts_model = CosyVoiceTTS(tts_config)
    tts_model.load(tts_config)
else:
    print("\nâš ï¸ TTS å·²ç¦ç”¨")

# LLM é…ç½®
llm_config = models_config.get("llm", {})
ollama_config = llm_config.get("ollama", {})

print("\n" + "=" * 60)
print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
print("=" * 60)

# ==================== API è·¯ç”± ====================


@app.route("/")
def index():
    """æœåŠ¡çŠ¶æ€"""
    return jsonify(
        {
            "success": True,
            "status": "running",
            "version": system_config.get("version", "1.0.0-preview"),
            "services": {
                "asr": {
                    "enabled": models_config.get("asr", {}).get("enabled", False),
                    "loaded": asr_model.is_loaded() if asr_model else False,
                    "type": models_config.get("asr", {}).get("type", "none"),
                },
                "tts": {
                    "enabled": models_config.get("tts", {}).get("enabled", False),
                    "loaded": tts_model.is_loaded() if tts_model else False,
                    "type": models_config.get("tts", {}).get("type", "none"),
                },
                "llm": {
                    "enabled": llm_config.get("enabled", False),
                    "type": llm_config.get("type", "none"),
                    "model": ollama_config.get("model", "none"),
                },
            },
            "endpoints": {
                "GET /": "æœåŠ¡çŠ¶æ€",
                "GET /voices": "è·å–éŸ³è‰²åˆ—è¡¨",
                "POST /asr": "è¯­éŸ³è¯†åˆ« (form-data: audio)",
                "POST /tts": "è¯­éŸ³åˆæˆ (json: {text, voice})",
                "POST /chat": "AIå¯¹è¯ (json: {message})",
                "POST /complete": "å®Œæ•´æµç¨‹ (form-data: audio)",
            },
        }
    )


@app.route("/voices", methods=["GET"])
def get_voices():
    """è·å–éŸ³è‰²åˆ—è¡¨"""
    if not tts_model or not tts_model.is_loaded():
        return jsonify({"success": False, "error": "TTSæ¨¡å‹æœªåŠ è½½", "voices": []}), 503

    try:
        voices = tts_model.get_voices()
        return jsonify({"success": True, "voices": voices, "count": len(voices)})
    except Exception as e:
        return jsonify({"success": False, "error": str(e), "voices": []}), 500


@app.route("/asr", methods=["POST"])
def asr():
    """
    è¯­éŸ³è¯†åˆ«

    Request (multipart/form-data):
        - audio: éŸ³é¢‘æ–‡ä»¶
        - language: è¯­è¨€ä»£ç  (optional, default: auto)

    Response (json):
        {
            "success": bool,
            "text": str,
            "language": str
        }
    """
    # æ£€æŸ¥æ¨¡å‹
    if not asr_model or not asr_model.is_loaded():
        return jsonify({"success": False, "error": "ASRæ¨¡å‹æœªåŠ è½½"}), 503

    # æ£€æŸ¥æ–‡ä»¶
    if "audio" not in request.files:
        return jsonify(
            {"success": False, "error": "æœªæä¾›éŸ³é¢‘æ–‡ä»¶ (field: audio)"}
        ), 400

    audio_file = request.files["audio"]
    language = request.form.get("language", "auto")

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    temp_path = os.path.join(tempfile.gettempdir(), audio_file.filename)
    audio_file.save(temp_path)

    try:
        # æ‰§è¡Œè¯†åˆ«
        result = asr_model.transcribe(temp_path, language)
        return jsonify(result)
    except Exception as e:
        return jsonify({"success": False, "error": f"è¯†åˆ«å¤±è´¥: {str(e)}"}), 500
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_path):
            os.remove(temp_path)


@app.route("/tts", methods=["POST"])
def tts():
    """
    è¯­éŸ³åˆæˆ

    Request (application/json):
        {
            "text": "è¦åˆæˆçš„æ–‡æœ¬",
            "voice": "éŸ³è‰²åç§°" (optional)
        }

    Response:
        - audio/wav æ–‡ä»¶
    """
    # æ£€æŸ¥æ¨¡å‹
    if not tts_model or not tts_model.is_loaded():
        return jsonify({"success": False, "error": "TTSæ¨¡å‹æœªåŠ è½½"}), 503

    # è·å–å‚æ•°
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "error": "è¯·æ±‚ä½“å¿…é¡»æ˜¯ JSON æ ¼å¼"}), 400

    text = data.get("text", "").strip()
    voice = data.get("voice")

    if not text:
        return jsonify({"success": False, "error": "æ–‡æœ¬ä¸èƒ½ä¸ºç©º"}), 400

    try:
        # æ‰§è¡Œåˆæˆ
        audio_path = tts_model.synthesize(text, voice)

        # è¿”å›éŸ³é¢‘æ–‡ä»¶
        return send_file(
            audio_path,
            mimetype="audio/wav",
            as_attachment=True,
            download_name="tts_output.wav",
        )
    except Exception as e:
        return jsonify({"success": False, "error": f"åˆæˆå¤±è´¥: {str(e)}"}), 500


@app.route("/chat", methods=["POST"])
def chat():
    """
    AIå¯¹è¯

    Request (application/json):
        {
            "message": "ç”¨æˆ·æ¶ˆæ¯",
            "history": [] (optional)
        }

    Response (json):
        {
            "success": bool,
            "response": str
        }
    """
    if not llm_config.get("enabled", True):
        return jsonify({"success": False, "error": "LLM å·²ç¦ç”¨"}), 503

    # è·å–å‚æ•°
    data = request.get_json()
    if not data:
        return jsonify({"success": False, "error": "è¯·æ±‚ä½“å¿…é¡»æ˜¯ JSON æ ¼å¼"}), 400

    message = data.get("message", "").strip()
    if not message:
        return jsonify({"success": False, "error": "æ¶ˆæ¯ä¸èƒ½ä¸ºç©º"}), 400

    # è·å–é…ç½®
    max_tokens = ollama_config.get("max_tokens", 80)
    system_prompt = ollama_config.get(
        "system_prompt", "è¯·ç”¨ç®€æ´çš„è¯­è¨€å›ç­”ï¼Œç¡®ä¿æ„æ€å®Œæ•´ã€‚å›ç­”è¦ç®€çŸ­ç²¾ç‚¼ï¼Œä¸è¦å†—é•¿ã€‚"
    )

    try:
        # ä½¿ç”¨ Chat API å’Œ System Message
        import requests

        payload = {
            "model": ollama_config.get("model", "gemma3:4b"),
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": message},
            ],
            "stream": False,
            "options": {
                "temperature": ollama_config.get("temperature", 0.7),
                "top_p": ollama_config.get("top_p", 0.9),
                "num_predict": max_tokens,
            },
        }

        response = requests.post(
            f"{ollama_config.get('url', 'http://localhost:11434')}/api/chat",
            json=payload,
            timeout=ollama_config.get("timeout", 60),
        )

        if response.status_code == 200:
            response_data = response.json()
            ai_response = response_data.get("message", {}).get("content", "")
            return jsonify(
                {
                    "success": True,
                    "response": ai_response,
                    "model": ollama_config.get("model"),
                    "max_tokens": max_tokens,
                }
            )
        else:
            return jsonify(
                {
                    "success": False,
                    "error": f"Ollama è°ƒç”¨å¤±è´¥: HTTP {response.status_code}",
                }
            ), 500

    except Exception as e:
        return jsonify({"success": False, "error": f"Ollama è°ƒç”¨å¤±è´¥: {str(e)}"}), 500

    except Exception as e:
        return jsonify({"success": False, "error": str(e)}), 500


@app.route("/complete", methods=["POST"])
def complete():
    """
    å®Œæ•´æµç¨‹ï¼šASR -> LLM -> TTS

    Request (multipart/form-data):
        - audio: éŸ³é¢‘æ–‡ä»¶
        - voice: éŸ³è‰²åç§° (optional)

    Response:
        - audio/wav æ–‡ä»¶
    """
    temp_files = []

    try:
        # Step 1: ASR
        print("\n[1/3] è¯­éŸ³è¯†åˆ«...")
        if "audio" not in request.files:
            return jsonify({"success": False, "error": "æœªæä¾›éŸ³é¢‘æ–‡ä»¶"}), 400

        # ä¿å­˜éŸ³é¢‘
        audio_file = request.files["audio"]
        temp_audio = os.path.join(tempfile.gettempdir(), audio_file.filename)
        audio_file.save(temp_audio)
        temp_files.append(temp_audio)

        # è¯†åˆ«
        if not asr_model or not asr_model.is_loaded():
            return jsonify({"success": False, "error": "ASRæ¨¡å‹æœªåŠ è½½"}), 503

        asr_result = asr_model.transcribe(temp_audio, "auto")
        if not asr_result.get("success"):
            return jsonify(
                {
                    "success": False,
                    "stage": "ASR",
                    "error": asr_result.get("error", "è¯†åˆ«å¤±è´¥"),
                }
            ), 500

        recognized_text = asr_result.get("text", "")
        print(f"   è¯†åˆ«ç»“æœ: {recognized_text[:50]}...")

        # Step 2: LLM
        print("[2/3] AIå¯¹è¯...")
        if not llm_config.get("enabled", True):
            return jsonify(
                {"success": False, "stage": "LLM", "error": "LLM å·²ç¦ç”¨"}
            ), 503

        # è·å–é…ç½®
        max_tokens = ollama_config.get("max_tokens", 80)
        system_prompt = ollama_config.get(
            "system_prompt",
            "è¯·ç”¨ç®€æ´çš„è¯­è¨€å›ç­”ï¼Œç¡®ä¿æ„æ€å®Œæ•´ã€‚å›ç­”è¦ç®€çŸ­ç²¾ç‚¼ï¼Œä¸è¦å†—é•¿ã€‚",
        )

        # ä½¿ç”¨ Chat API
        try:
            import requests

            payload = {
                "model": ollama_config.get("model", "gemma3:4b"),
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": recognized_text},
                ],
                "stream": False,
                "options": {
                    "temperature": ollama_config.get("temperature", 0.7),
                    "num_predict": max_tokens,
                },
            }

            response = requests.post(
                f"{ollama_config.get('url', 'http://localhost:11434')}/api/chat",
                json=payload,
                timeout=ollama_config.get("timeout", 60),
            )

            if response.status_code != 200:
                return jsonify(
                    {
                        "success": False,
                        "stage": "LLM",
                        "error": f"LLM è°ƒç”¨å¤±è´¥: HTTP {response.status_code}",
                    }
                ), 500

            llm_data = response.json()
            ai_response = llm_data.get("message", {}).get("content", "")
            print(f"   AIå›å¤: {ai_response[:50]}...")

        except Exception as e:
            return jsonify(
                {"success": False, "stage": "LLM", "error": f"LLM è°ƒç”¨å¤±è´¥: {str(e)}"}
            ), 500

        # Step 3: TTS
        print("[3/3] è¯­éŸ³åˆæˆ...")
        if not tts_model or not tts_model.is_loaded():
            return jsonify(
                {"success": False, "stage": "TTS", "error": "TTSæ¨¡å‹æœªåŠ è½½"}
            ), 503

        voice = request.form.get("voice")
        audio_path = tts_model.synthesize(ai_response, voice)

        print("âœ… æµç¨‹å®Œæˆ")

        # è¿”å›éŸ³é¢‘
        return send_file(
            audio_path,
            mimetype="audio/wav",
            as_attachment=True,
            download_name="response.wav",
        )

    except Exception as e:
        import traceback

        traceback.print_exc()
        return jsonify({"success": False, "error": str(e)}), 500
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for f in temp_files:
            if os.path.exists(f):
                os.remove(f)


# ==================== å¯åŠ¨æœåŠ¡ ====================

if __name__ == "__main__":
    port = system_config.get("port", 7861)
    debug = system_config.get("debug", False)

    print(f"\nğŸŒ å¯åŠ¨ API æœåŠ¡...")
    print(f"   åœ°å€: http://0.0.0.0:{port}")
    print(f"   è°ƒè¯•æ¨¡å¼: {debug}")
    print("\næŒ‰ Ctrl+C åœæ­¢æœåŠ¡\n")

    app.run(host="0.0.0.0", port=port, debug=debug)
